{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Spark: Make sure your environment is configured properly\n\nThis notebook is just intended to check if you are able to access spark and use it though a jupyter notebook. So, you dont need to pay any attention to the code in it. Just go ahead and run all the cells and check to see if you are able to instanciate spark and use it.\n\n* I am using Azure Notebooks for these notebooks, as I can access it from anywhere.\n* Note that the persistance of the notebook instance is only 60 days from the time it goes inactive. \n* Make sure you don't store any state here. Make use of \n    - `AWS S3` \n    - `GCP GCS`\n    - `Azure OS`"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Imports\nfrom pyspark.context import SparkContext\nfrom pyspark.sql import SparkSession\nimport random",
      "execution_count": 34,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Initialize spark context\nsc = SparkContext.getOrCreate()\nspark = SparkSession(sc)\nsc\nspark",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 35,
          "data": {
            "text/html": "\n            <div>\n                <p><b>SparkSession - in-memory</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"http://10.36.20.194:4040\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v2.4.3</code></dd>\n              <dt>Master</dt>\n                <dd><code>local[*]</code></dd>\n              <dt>AppName</dt>\n                <dd><code>pyspark-shell</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        ",
            "text/plain": "<pyspark.sql.session.SparkSession at 0x7fd226367f98>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Creating a datafrom from a range of numbers\ndf = spark.range(10).toDF(\"numbers\")",
      "execution_count": 36,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Printing the schema\ndf.printSchema()",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": "root\n |-- numbers: long (nullable = false)\n\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Displaying the dataframe\ndf.show()",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": "+-------+\n|numbers|\n+-------+\n|      0|\n|      1|\n|      2|\n|      3|\n|      4|\n|      5|\n|      6|\n|      7|\n|      8|\n|      9|\n+-------+\n\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Displaying tuples\ndf.take(2)",
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 39,
          "data": {
            "text/plain": "[Row(numbers=0), Row(numbers=1)]"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Counting the number of entries in the DF\ndf.count()",
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 40,
          "data": {
            "text/plain": "10"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Stopping spark context\nsc.stop()",
      "execution_count": 41,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "`Info: If all of the above cells have executed sucessfully, please go ahead and start of with the book as mentioned in the readme.md`"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}